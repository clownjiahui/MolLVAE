{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n",
      "Loading trained model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LVAE(\n",
       "  (embedding): Embedding(37, 128, padding_idx=35)\n",
       "  (encoder): LSTM_encoder(\n",
       "    (embedding): Embedding(37, 128, padding_idx=35)\n",
       "    (lstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): LSTM_decoder(\n",
       "    (x_emb): Embedding(37, 128, padding_idx=35)\n",
       "    (map_z2hc): Linear(in_features=28, out_features=512, bias=True)\n",
       "    (decoder_fc): Linear(in_features=256, out_features=37, bias=True)\n",
       "    (lstm): LSTM(156, 256, batch_first=True)\n",
       "  )\n",
       "  (top_down_layers): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layer1): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (layer2): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (mu): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (var): Linear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (layer1): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (var): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bottom_up_layers): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layer1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mu): Linear(in_features=128, out_features=16, bias=True)\n",
       "      (var): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (layer1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (mu): Linear(in_features=64, out_features=8, bias=True)\n",
       "      (var): Linear(in_features=64, out_features=8, bias=True)\n",
       "    )\n",
       "    (2): MLP(\n",
       "      (layer1): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (layer2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (mu): Linear(in_features=32, out_features=4, bias=True)\n",
       "      (var): Linear(in_features=32, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work01/home/wxxie/project/drug-gen/mollvae/MolLVAE/code\")\n",
    "from dataset import DatasetSplit\n",
    "from opt import get_parser\n",
    "from model.model import LVAE\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from moses.utils import CircularBuffer\n",
    "\n",
    "########## config\n",
    "\n",
    "parser = get_parser()\n",
    "config = parser.parse_args(\"--device cuda:0 \\\n",
    "                           --n_enc_zs 1 --n_dec_xs 1 --gen_bsz 128\".split())\n",
    "\n",
    "device = torch.device(config.device)\n",
    "set_seed(config.seed)\n",
    "\n",
    "#n_sample = config.n_sample\n",
    "test_csv = config.test_load\n",
    "load_model_from = \"../res/exp/model_049.pt\"\n",
    "\n",
    "n_latcode = config.n_enc_zs # get n_latcode latent codes for each mol\n",
    "n_dec_xs = config.n_dec_xs\n",
    "gen_bsz = config.gen_bsz\n",
    "max_len = config.max_len\n",
    "\n",
    "########## utils\n",
    "\n",
    "def tensor2string_ad(tensor, vocab):\n",
    "    \"\"\" Adapted from model.tensor2string. Consider pad indx in tensor. \"\"\"\n",
    "    \n",
    "    ids = tensor.tolist()\n",
    "    if vocab.pad in ids:\n",
    "        pad_idx = ids.index(vocab.pad)\n",
    "        ids = ids[:pad_idx]\n",
    "    string = vocab.ids2string(ids, rem_bos=True, rem_eos=True)\n",
    "    return string\n",
    "\n",
    "\n",
    "########## get data and load trained model\n",
    "\n",
    "test_split = DatasetSplit(\"test\", test_csv)\n",
    "test_dataloader = test_split.get_dataloader(batch_size=gen_bsz, shuffle=False)\n",
    "\n",
    "vocab = test_split._vocab\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "model = LVAE(vocab, config)\n",
    "model.load_state_dict(torch.load(load_model_from))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n",
      "Loading trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871/871 [02:03<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set reconstruction rate: 2160.045924225029%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "########## Check test set reconstruction rate\n",
    "########## v1\n",
    "\n",
    "success_cnt = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        batch = (batch[0].to(device), batch[1])\n",
    "        \n",
    "        _,h = model.encoder(batch)\n",
    "        \n",
    "        z_mu_q_d, z_log_var_q_d = model.bottom_up(h)\n",
    "        \n",
    "        ## sample n_latcode times in top ladder z\n",
    "        qd_mu_top = z_mu_q_d[-1].unsqueeze(1).repeat(1, n_latcode, 1) # (bsz, n_latcode, z_size[-1])\n",
    "        qd_logvar_top = z_log_var_q_d[-1].unsqueeze(1).repeat(1, n_latcode, 1)\n",
    "        z_sample_top = model.sample_z(qd_mu_top, qd_logvar_top)\n",
    "        \n",
    "        \n",
    "        ## Input SMILES for ref\n",
    "        padded_x, _ = batch\n",
    "        input_seqs = []\n",
    "        for s in padded_x:\n",
    "            input_seqs.append(tensor2string_ad(s, vocab))     \n",
    "        \n",
    "        for j in range(n_latcode):\n",
    "            \n",
    "            z_sample = []\n",
    "            z_sample.append(z_sample_top[:,j,:])\n",
    "            \n",
    "            _,_,_,_,samples = model.top_down(z_mu_q_d,z_log_var_q_d, z_sample=z_sample, mode=\"eval\")\n",
    "            \n",
    "            recon_seqs = model.sample(len(input_seqs), max_len=max_len, z_in=samples)\n",
    "            \n",
    "            \n",
    "            for k, (r_s,s) in enumerate(zip(recon_seqs, input_seqs)): # loop over mols\n",
    "                if r_s == s:\n",
    "                    success_cnt += 1\n",
    "\n",
    "\n",
    "total_trials = len(test_split.split_dataset.data) * n_latcode * n_dec_xs\n",
    "print(f\"Test set reconstruction rate: {1.*success_cnt / total_trials * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871/871 [02:02<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set reconstruction rate: 17.03599989229651%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########## Check test set reconstruction rate\n",
    "########## v2\n",
    "\n",
    "success_cnt = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        batch = (batch[0].to(device), batch[1])\n",
    "        \n",
    "        ## Input SMILES for ref\n",
    "        padded_x, _ = batch\n",
    "        input_seqs = []\n",
    "        for s in padded_x:\n",
    "            input_seqs.append(tensor2string_ad(s, vocab))         \n",
    "        \n",
    "        _,h = model.encoder(batch)\n",
    "        z,_ = model.forward_latent(h) # z already concated\n",
    "        \n",
    "        recon_seqs = model.sample(len(input_seqs), max_len=max_len, z_in=z, concated=True)\n",
    "        \n",
    "        success_cnt += sum(1 for r_s,s in zip(recon_seqs,input_seqs) if r_s==s)\n",
    "        \n",
    "total_trials = len(test_split.split_dataset.data) * n_latcode * n_dec_xs\n",
    "print(f\"Test set reconstruction rate: {1.*success_cnt / total_trials * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CircularBuffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-288710750973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m########## check recon_loss for test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecon_loss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCircularBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_buf_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CircularBuffer' is not defined"
     ]
    }
   ],
   "source": [
    "########## check recon_loss for test set\n",
    "\n",
    "recon_loss_values = CircularBuffer(config.loss_buf_sz)\n",
    "data = tqdm(test_dataloader)\n",
    "for batch in data:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        batch = (batch[0].to(device), batch[1])\n",
    "        kl_loss, recon_loss = model(batch)\n",
    "        \n",
    "        recon_loss_values.add(recon_loss.item())\n",
    "        recon_loss_value = recon_loss_values.mean()\n",
    "        \n",
    "        postfix = [f'recon={recon_loss_value:.5f})']\n",
    "        data.set_postfix_str(' '.join(postfix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16886112532198858"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_cnt/len(test_split.split_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "val = [1 for s in recon_seqs if Chem.MolFromSmiles(s)]\n",
    "sum(val)/len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC1CN(c2ccc(N)cc2)C(=O)c2cc(CN3CCS(=O)(=O)C(N)C(C)S3)c(F)c(Cl)c2=N1',\n",
       " 'CCc1cn2c(c1S(=O)(=O)N1CCN(C(C)C)nn2-c1ccc(OC)c(OC)c1)S(C)(=O)=O',\n",
       " 'CCN(CCO)CC(C)C1CC2OC3(C)C(O)C(C)(O)CCC4CC(C)C24CC(C)C(C1=O)C3',\n",
       " 'Cc1ccc(-n2cnc(NC=C3C=CS(=N)(=O)N3)n2)c(N2CCN(c3cccc(C)c3)CC2)c1',\n",
       " 'O=C(C1CCCN1C(=O)Oc1ccc(C(=O)N2CCCN3CCCC3(Cc3ccccc3)CC2)cc1)NCCC',\n",
       " 'Cn1nccc1CN1C(NC(=O)C(Cl)(Cl)c2c[nH]cnc2=O)C(=O)c2ccccc2N1',\n",
       " 'CCC1(O)C=C2CCC3(CC1)CCCC3c1ccc(CN4CCC5(CO3)C(=O)N4)cc1C2=O',\n",
       " 'CC(Cn1c2c(=O)n(-c3ccc(F)c(-c4ccccc4C)cn3)cc2c1CCCO)C(=O)O',\n",
       " 'COc1ccccc1C1C(=O)NC(c2ccc(C)cc2)N(c1ccnc(F)c1)c1ccccc1',\n",
       " 'COc1ccc(C(=O)N2CCCC3(CCN(C(=O)c4cncc(C)c4C)C3)C2)cc1',\n",
       " 'NS(=O)(=O)c1ccc(-n2nc(C(F)(F)F)cc3c2-c2ccccc2-3)s1',\n",
       " 'Cc1ccc(S(=O)(=O)Nc2ccc3c(c2)C(=O)C(=O)c3ccccc2S3)cc1',\n",
       " 'COc1cccc(C2CS(=O)(Nc3ccc(F)cc3)CN(C)c3ccc(O)cc32)c1',\n",
       " 'CC(C)CC(NC(=O)c1n[nH]c2cc(C(F)(F)F)cn2c1O)c1ccccc1F',\n",
       " 'CC(C)(C)OC(=O)N1CCN(C(=O)SCn2c(=O)cc(-c3scs3)ncc2=O)C1',\n",
       " 'COc1ccc(Cc2nc(-c3ccc(OCCC(=O)NCCN)cc3)co2)cc1Br',\n",
       " 'COc1ccc(-c2ccc3c(N)c(C(=O)Nc4ccc(F)cc4)nc3s2)cc1',\n",
       " 'COc1cccc(CNc2nc3ccccn3c(=O)c2c2Cl)S(=O)(=O)CC1',\n",
       " 'COc1c(C(=O)Cc2ccc3c(c2)OCO3)ccc2CC(=O)C=CC12C',\n",
       " 'Cn1cc(C(=O)Nc2ccc3c(c2)C(C)Nc2nc3ccccc3n2)CCC1',\n",
       " 'O=C(c1ccc(Oc2ccc(Cl)cc2)cn1)N1CCC(N2CCCC2)CC1',\n",
       " 'CC(CO)NC1CC(=O)c2cccnc2-c2c1cc1c3c(cc2C1)CNC3',\n",
       " 'COc1ccc2c(c1)OCCC2CN1CCc2c(c3cc(O)ccc3CCC2)OC1',\n",
       " 'O=C(Nc1cccc(NC(=O)c2ccc(O)cc2)c1O)c1ccc(F)cc1',\n",
       " 'COc1ccc2cc(C=CC(=O)NC3C(=O)N(C)CCCO3)ccc2c1O',\n",
       " 'O=C1CC2(CCN(S(=O)(=O)c3ccccc3)CC2=O)CO1',\n",
       " 'COc1cc(C=C[S+]2OCOC)cc2c(OC)c1C(=O)c1ccccc1Br',\n",
       " 'CCOC(=O)C1CN(S(=O)(=O)c2ccc(C)cc2)c2ccccc2O1',\n",
       " 'Cc1c(C)c2c(c(C)c1OC(F)(F)F)C(C)(C(C)C)OC2',\n",
       " 'COc1ccccc1CNC(=O)COC(=O)c1cccc(-n2cncn2)n1',\n",
       " 'CN1CCC(c2cc(SCC(C)(C)C)oc2)Cc2cc(O)ccc2O1',\n",
       " 'Cc1cc(F)ccc1-c1cc(C(=O)NCc2ccccc2)[nH]n1',\n",
       " 'COc1ccc2cccc(CCNC(=O)C3CN(C)C(=O)C3)c2c1',\n",
       " 'CN(C)C(=O)Nc1ccc2c(CCc3cccc(F)c3)ccc(=O)c2c1',\n",
       " 'O=[N+]([O-])c1ccccc1NC1CCN(Cc2ccccc2)CC1',\n",
       " 'O=C(c1ccc(CNc2[nH]ccc2Br)c2cc(F)ccc12)N',\n",
       " 'CC(=NNC(=S)NC1=CC(N)=NO2)c1cccc1C',\n",
       " 'Cc1nc(C2CCCN2CCC(=O)N2CCc3ccccc32)on1',\n",
       " 'COc1ccc(Nc2ncnc3scc(-c4ccccc4)c23)cc1',\n",
       " 'Nc1nc(-c2cccc(C(F)(F)F)c2)cc(=O)[nH]1',\n",
       " 'CC(C)(C)c1nc(C2CCN(CCN)c3cnccn32)sc1=O',\n",
       " 'O=C(Cc1ccccc1)NC1CN(CCC(O)CC2CC2)OC1',\n",
       " 'CSc1nccc(-c2c(-c3ccc(Cl)cc3)noc2SC)n1',\n",
       " 'O=C(OCCN1CCCCC1)C(c1ccccc1)N1CCCCC1',\n",
       " 'CN(C)N=Cc1cn2cc3c(cc2c1)OCCS3C(=O)NO',\n",
       " 'CC(C)N1CCC(Nc2cc(N)nc3ccccc23)N1N',\n",
       " 'Nc1ccccc1CN1C(=O)C2C3CCC(O3)C2C1=O',\n",
       " 'CCn1cnnc1CNC(=O)NCC(O)c1ccc(OC)cc1',\n",
       " 'Nc1ncccc1-n1c(Cc2cnc(N)nc2)ccn1',\n",
       " 'O=C(CC1CCCCC1)NCc1nc(-c2ccccc2)no1',\n",
       " 'O=C(O)c1ccccc1C(=O)NNc1ccc(F)cc1',\n",
       " 'CC1CCc2nc3sc4c(c3c(N)c2C1)CCCC4',\n",
       " 'CC1(C)C=Cc2c(ccc3c2OCC(C)O3)cc1O',\n",
       " 'Cc1ccccc1SC(c1ccccc1)C1NCCCO1',\n",
       " 'O=C(O)c1c(O)cccc1OCCCOc1ccccc1',\n",
       " 'OCC1CN(Cc2ccc(F)cc2)CC(O)C1O',\n",
       " 'OC1CCN2Cc3ccccc3N=C21']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work01/home/wxxie/project/drug-gen/mollvae/MolLVAE/code\")\n",
    "from dataset import DatasetSplit\n",
    "from opt import get_parser\n",
    "from model.model import LVAE\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(clip_grad=50, dec_hid_sz=256, dec_n_layer=1, dec_type='lstm', device='cuda:0', dropout=0.1, emb_sz=128, enc_bidirectional=True, enc_hidden_size=256, enc_num_layers=1, enc_sorted_seq=True, enc_type='lstm', gen_bsz=128, kl_anr_type='cyclic', kl_e_start=0, kl_n_cycle=1, kl_w_end=0.001, kl_w_start=0.0001, ladder_d_size=[128, 64, 32], ladder_z2z_layer_size=[8, 16], ladder_z_size=[16, 8, 4], log_path=None, loss_buf_sz=20, lr_anr_type='SGDR', lr_end=1e-06, lr_mult_coeff=1, lr_n_restarts=5, lr_period=10, lr_start=0.00030000000000000003, max_len=150, model_save=None, n_dec_xs=1, n_enc_zs=10, n_epoch=100, n_sample=1000, ratio=0.2, save_frequency=10, seed=56, test_load='../data/test.csv', train_bsz=512, train_load='../data/train.csv', valid_load='../data/valid.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## config\n",
    "\n",
    "parser = get_parser()\n",
    "config = parser.parse_args(\"--device cuda:0 \\\n",
    "                           --n_enc_zs 10 --n_dec_xs 1 --gen_bsz 128\".split())\n",
    "\n",
    "device = torch.device(config.device)\n",
    "set_seed(config.seed)\n",
    "\n",
    "#n_sample = config.n_sample\n",
    "test_csv = config.test_load\n",
    "load_model_from = \"../res/exp/model_049.pt\"\n",
    "\n",
    "n_latcode = config.n_enc_zs # get n_latcode latent codes for each mol\n",
    "n_dec_xs = config.n_dec_xs\n",
    "gen_bsz = config.gen_bsz\n",
    "max_len = config.max_len\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n",
      "Loading trained model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LVAE(\n",
       "  (embedding): Embedding(37, 128, padding_idx=35)\n",
       "  (encoder): LSTM_encoder(\n",
       "    (embedding): Embedding(37, 128, padding_idx=35)\n",
       "    (lstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): LSTM_decoder(\n",
       "    (x_emb): Embedding(37, 128, padding_idx=35)\n",
       "    (map_z2hc): Linear(in_features=28, out_features=512, bias=True)\n",
       "    (decoder_fc): Linear(in_features=256, out_features=37, bias=True)\n",
       "    (lstm): LSTM(156, 256, batch_first=True)\n",
       "  )\n",
       "  (top_down_layers): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layer1): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (layer2): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (mu): Linear(in_features=8, out_features=8, bias=True)\n",
       "      (var): Linear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (layer1): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (layer2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (mu): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (var): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bottom_up_layers): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layer1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (mu): Linear(in_features=128, out_features=16, bias=True)\n",
       "      (var): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (layer1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (layer2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (mu): Linear(in_features=64, out_features=8, bias=True)\n",
       "      (var): Linear(in_features=64, out_features=8, bias=True)\n",
       "    )\n",
       "    (2): MLP(\n",
       "      (layer1): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (layer2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (mu): Linear(in_features=32, out_features=4, bias=True)\n",
       "      (var): Linear(in_features=32, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "########## get data and load trained model\n",
    "\n",
    "test_split = DatasetSplit(\"test\", test_csv)\n",
    "test_dataloader = test_split.get_dataloader(batch_size=gen_bsz, shuffle=False)\n",
    "\n",
    "vocab = test_split._vocab\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "model = LVAE(vocab, config)\n",
    "model.load_state_dict(torch.load(load_model_from))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## utils\n",
    "\n",
    "def tensor2string_ad(tensor, vocab):\n",
    "    ids = tensor.tolist()\n",
    "    if vocab.pad in ids:\n",
    "        pad_idx = ids.index(vocab.pad)\n",
    "        ids = ids[:pad_idx]\n",
    "    string = vocab.ids2string(ids, rem_bos=True, rem_eos=True)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab...\n"
     ]
    }
   ],
   "source": [
    "train_split = DatasetSplit(\"train\", config.train_load)\n",
    "train_dataloader = train_split.get_dataloader(batch_size=gen_bsz, shuffle=False)\n",
    "test_data_loader = train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/871 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set reconstruction rate: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(test_dataloader):\n",
    "    \n",
    "    success_cnt = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        batch = (batch[0].to(device), batch[1])\n",
    "        \n",
    "        _,h = model.encoder(batch)\n",
    "        \n",
    "        z_mu_q_d, z_log_var_q_d = model.bottom_up(h)\n",
    "        \n",
    "        ## get 10 encoded latent codes for each mol\n",
    "        qd_mu_top = z_mu_q_d[-1].unsqueeze(1).repeat(1, n_latcode, 1) # (bsz, n_latcode, z_size[-1])\n",
    "        qd_logvar_top = z_log_var_q_d[-1].unsqueeze(1).repeat(1, n_latcode, 1)\n",
    "        z_sample_top = model.sample_z(qd_mu_top, qd_logvar_top)\n",
    "        \n",
    "        ## get input smiles\n",
    "        seqs,_ = batch\n",
    "        input_seqs = []\n",
    "        for s in seqs:\n",
    "            input_seqs.append(tensor2string_ad(s, vocab))\n",
    "        #print(input_seqs)        \n",
    "        \n",
    "        success_batch_cnt = [0 for _ in range(gen_bsz)]\n",
    "        for j in range(n_latcode):\n",
    "            \n",
    "            z_sample = []\n",
    "            z_sample.append(z_sample_top[:,j,:])\n",
    "            \n",
    "            _,_,_,_,samples = model.top_down(z_mu_q_d,z_log_var_q_d, z_sample=z_sample, mode=\"eval\")\n",
    "            \n",
    "            recon_seqs = model.sample(gen_bsz, max_len=max_len, z_in=samples)\n",
    "            \n",
    "            for k, (r_s,s) in enumerate(zip(recon_seqs, input_seqs)): # loop over mols\n",
    "                if r_s == s:\n",
    "                    success_batch_cnt[k] += 1\n",
    "             \n",
    "        #? debug\n",
    "        break\n",
    "        \n",
    "    success_cnt += sum(success_batch_cnt)\n",
    "\n",
    "n_x = gen_bsz #len(test_dataloader)\n",
    "total_trials = n_x * n_latcode * n_dec_xs\n",
    "print(f\"Test set reconstruction rate: {1.*success_cnt / total_trials * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "tof = [1 for s in recon_seqs if Chem.MolFromSmiles(s)]\n",
    "\n",
    "sum(tof)/len(tof)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181],\n",
       "        [ 0.0304, -0.0196,  0.0056, -0.0181]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_mu_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC1CN(c2ccc(F)cc2C(F)(F)F)CCN1S(=O)(=O)c1ncc(C(O)(C(N)=O)C(F)(F)F)s1',\n",
       " 'CCc1c2c(nn1C(=O)N(C)C)C(=O)N(c1cc(C)c(=O)n(C)c1)C2c1ccc(Cl)cc1',\n",
       " 'CC(CCC(=O)O)C1CCC2(C)C3C(=O)CC4C(C)(C)C(O)CCC4(C)C3C(=O)CC12C',\n",
       " 'Cc1ccc(-n2nccn2)c(C(=O)N2CCN(c3ncc(C(F)(F)F)c(C)n3)CCC2C)c1',\n",
       " 'O=C(C1CCCN1C(=O)c1ccc(C(=O)N2CCCC2C(=O)N2CCCC2)cc1)N1CCCC1',\n",
       " 'Cn1cncc1CN1CC(N(CC(N)=O)S(=O)(=O)c2ccccn2)Cc2cc(C#N)ccc21',\n",
       " 'CC#CC1(O)CCC2C3CCC4=CC(=O)CCC4=C3C(c3ccc(N(C)C)cc3)=CC21C',\n",
       " 'CC(Cn1c2c(c3cc(NS(=O)(=O)c4ccc(F)cc4)ccc31)CCCC2)C(=O)O',\n",
       " 'COc1ccccc1C1C(=O)N(C)c2ccc(C(F)(F)F)cc2N(c2ccccc2)C1=O',\n",
       " 'COc1ccc(C(=O)N2CCCC3(CCN(C(=O)Nc4cccc(C#N)c4)C3)C2)cc1',\n",
       " 'NS(=O)(=O)c1ccc(-n2nc(C(F)(F)F)cc2-c2cc3ccccc3o2)cc1',\n",
       " 'Cc1ccc(S(=O)(=O)Nc2ccc3c(c2)C(=O)C(=O)c2ccccc2-3)cc1',\n",
       " 'COc1cccc(C2C([N+](=O)[O-])=C(N)Oc3cc(C)oc(=O)c32)c1',\n",
       " 'CC(C)CC(NC(=O)c1cn(-c2ccncc2)c(-c2ccccc2)n1)C(=O)O',\n",
       " 'CC(C)(C)OC(=O)N1CCN(C(=S)SCc2cn(Cc3ccccc3F)nn2)CC1',\n",
       " 'COc1ccc(Cc2nc(-c3ccc(OCCCCN(C)C)cc3)c[nH]c2=O)cc1',\n",
       " 'COc1ccc(-c2ccc3c(N)c(C(=O)Nc4ccc(F)cc4)sc3n2)cc1',\n",
       " 'COc1cccc(CN2c3nccc[n+]3CC2(O)c2ccc(Cl)c(Cl)c2)c1',\n",
       " 'COc1c(C(=O)Cc2ccc3c(c2)OCCO3)ccc2c1C=CC(C)(C)O2',\n",
       " 'Cn1cc(C(=O)Nc2ccc3c(c2)CN(C(=O)c2ccco2)CC3)nn1',\n",
       " 'O=C(c1ccc(Oc2ccc(Cl)cc2)cn1)N1CCCN(C2CCC2)CC1',\n",
       " 'CC(CO)NC(=O)C1C=C2c3cccc4[nH]cc(c34)CC2N(C)C1',\n",
       " 'COc1ccc2c(c1)CCOC21CCN(Cc2ccc3c(c2)OCCO3)CC1',\n",
       " 'O=C(Nc1cccc(NC(=O)c2ccc(O)cc2)c1)c1ccc(O)cc1',\n",
       " 'COc1ccc2cc(C=CC(=O)NC3=C(C(=O)O)CCCC3)ccc2c1',\n",
       " 'O=C1CC2(CCN(S(=O)(=O)c3ccccc3)CC2)Oc2ccccc21',\n",
       " 'COc1cc(C=Cc2ccc(O)cc2)c(OC)cc1C=Cc1ccc(O)cc1',\n",
       " 'CCOC(=O)C1CN(S(=O)(=O)c2ccc(C)cc2)c2ccccc2O1',\n",
       " 'Cc1c(C)c2c(c(C)c1O)C(C[N+](C)(C)C)C(C)(C)O2',\n",
       " 'COc1ccccc1CNC(=O)COC(=O)c1cccc(-n2cnnn2)c1',\n",
       " 'COC(CCl)c1cn(C2CC(O)C(CO)O2)c(=O)[nH]c1=O',\n",
       " 'Cc1cc(F)ccc1-c1cc(C(=O)NCc2ccccc2)[nH]n1',\n",
       " 'COc1ccc2cccc(CCNC(=O)C3CN(C(C)=O)C3)c2c1',\n",
       " 'CN(C)C(=O)N1Cc2cc(I)ccc2C(c2cccc(O)c2)C1',\n",
       " 'O=[N+]([O-])c1ccccc1NC1CCN(Cc2ccccc2)CC1',\n",
       " 'O=S1(=O)Nc2c(cc(Br)c3cccnc23)-c2ccccc21',\n",
       " 'CC(=NNC(=O)NNC(=O)Nc1ccccc1Cl)c1ccccn1',\n",
       " 'Cc1nc(C2CCCN2CCC(=O)N2CCc3ccccc32)no1',\n",
       " 'COc1ccc(Nc2ncnc3scc(-c4ccccc4)c23)cc1',\n",
       " 'Nc1nc(-c2cccc(C(F)(F)F)c2)cc(=O)[nH]1',\n",
       " 'CC(C)(C)c1nc(CN2CCCC(Cn3cncn3)C2)cs1',\n",
       " 'O=C(Cc1ccccc1Cl)N1CCN(CC(O)COCCO)CC1',\n",
       " 'CSc1nccc(-c2c(-c3ccc(Cl)cc3)noc2C)n1',\n",
       " 'O=C(OCCN1CCCCC1)C(c1ccccc1)N1CCCCC1',\n",
       " 'CN(C)N=Nc1ccc2c3c(cccc13)C(=O)NC2=O',\n",
       " 'CC(C)N1CCC(Nc2ccn(Cc3ccccn3)n2)C1=O',\n",
       " 'Nc1ccccc1CN1C(=O)C2C3CCC(O3)C2C1=O',\n",
       " 'CCn1cnnc1CNC(=O)NCC(O)c1ccc(OC)cc1',\n",
       " 'Nc1nccc(-c2csc(Nc3ccc(Cl)cc3)n2)n1',\n",
       " 'O=C(CC1CCCCC1)NCc1nc(-c2ccccc2)no1',\n",
       " 'O=C(O)c1ccccc1C(=O)NNc1ccc(F)cc1',\n",
       " 'CC1CCc2nc3sc4c(c3c(N)c2C1)CCCC4',\n",
       " 'CC1(C)C=Cc2c(ccc3c2OCC(O)C3)O1',\n",
       " 'Cc1ccccc1SC(c1ccccc1)C1CNCCO1',\n",
       " 'O=C(O)c1c(O)cccc1OCCCc1ccccc1',\n",
       " 'OCC1CN(Cc2ccc(F)cc2)CC(O)C1O',\n",
       " 'OC1CCN2Cc3ccccc3N=C12']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "m=Chem.MolFromSmiles('OC1CCN2Cc3ccccc3N=C12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f595c319350>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1563,  0.8204,  0.3920, -0.4285]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sample_top[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Cc1cc(C(=O)N2CC3CC(=NNC(C)CS(=O)(=O)NCCCCC3)COC)nc1)c1', 'Oc1ccc(NN2CCOCC34cc(-c4ccccc4C)nc33)CCC2)c1']\n",
    "['Cc1cccc(N2CCN(CC(=O)Nc3ccccc3[N+](=O)[O-])CC2)c1C', 'Nc1cnc(-c2ccc(C3CCC3)c(OCC3CNC3)c2F)cn1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=seqs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cc1cccc(N2CCN(CC(=O)Nc3ccccc3[N+](=O)[O-])CC2)c1C',\n",
       " 'Nc1cnc(-c2ccc(C3CCC3)c(OCC3CNC3)c2F)cn1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split.split_dataset.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b0aaf17877c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msmis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpad_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msmis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "seqs,_ = batch\n",
    "smis = []\n",
    "for s in seqs:\n",
    "    pad_idx = s.index(vocab.pad)\n",
    "    smis.append(model.tensor2string(s[:pad_idx]))\n",
    "print(smis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.randn(1,2)\n",
    "a=torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3853, 1.5616]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3853, -0.4384]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1484, 0.1922]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.randn(2,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5933, -0.1151,  0.5760,  1.1554],\n",
       "         [ 0.2207,  0.7938,  0.0841, -1.7516]],\n",
       "\n",
       "        [[ 0.9030, -0.2162, -0.6445,  0.8059],\n",
       "         [-0.7157, -0.5792,  0.0085,  0.6672]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4067,  0.8849,  1.5760,  2.1554],\n",
       "         [ 1.2207,  1.7938,  1.0841, -0.7516]],\n",
       "\n",
       "        [[ 1.9030,  0.7838,  0.3555,  1.8059],\n",
       "         [ 0.2843,  0.4208,  1.0085,  1.6672]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2,4)+t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hiensg)",
   "language": "python",
   "name": "hiensg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
