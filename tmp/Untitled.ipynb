{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change to global import\n",
    "import sys\n",
    "sys.path.append(\"/work01/home/wxxie/project/drug-gen/mollvae/MolLVAE/code\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.decoders.LSTM_decoder import LSTM_decoder\n",
    "from model.encoders.LSTM_encoder import LSTM_encoder\n",
    "\n",
    "class LVAE(torch.nn.Module):\n",
    "    def __init__(self,vocab,config):\n",
    "        super(LVAE,self).__init__()\n",
    "        for ss in ('bos', 'eos', 'unk', 'pad'):\n",
    "            setattr(self, ss, getattr(vocab, ss))\n",
    "        self.d_size = config.ladder_d_size\n",
    "        self.z_size = config.ladder_z_size\n",
    "        self.z2z_layer_size = config.ladder_z2z_layer_size\n",
    "        self.z_reverse_size = list(reversed(config.ladder_z_size))\n",
    "        self.vocab = vocab\n",
    "        # Word embeddings layer\n",
    "        self.embedding = nn.Embedding(len(self.vocab.i2c),config.emb_sz,self.vocab.pad)\n",
    "\n",
    "        # Encoder\n",
    "        if config.enc_type == 'lstm':\n",
    "            self.encoder = LSTM_encoder(self.embedding,self.vocab,config)\n",
    "            self.ladder_input_size = config.enc_hidden_size * (1 + int(config.enc_bidirectional))\n",
    "        else :\n",
    "            raise ValueError(\n",
    "                \"Invalid encoder_type\"\n",
    "            )\n",
    "\n",
    "        # Decoder\n",
    "        if config.dec_type == 'lstm':\n",
    "            self.decoder = LSTM_decoder(self.vocab,self.embedding,config,config.ladder_z_size[0])\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid decoder_type\"\n",
    "            )\n",
    "\n",
    "        #ladder\n",
    "        self.top_down_layers = nn.ModuleList()\n",
    "        self.bottom_up_layers = nn.ModuleList()\n",
    "\n",
    "        #get a list contain bottom up layers,which used to generate z_mu_q_d and z_log_var_q_d\n",
    "        for i in range(len(self.d_size)):\n",
    "            if i == 0:\n",
    "                self.bottom_up_layers.append(MLP(in_size=self.ladder_input_size,layer_size=self.d_size[i],out_size=self.z_size[i]))\n",
    "            else:\n",
    "                self.bottom_up_layers.append(MLP(in_size=self.d_size[i-1],layer_size=self.d_size[i],out_size=self.z_size[i]))\n",
    "\n",
    "        #get a list contain top down layers,which used to generate z_mu_p and z_log_var_p\n",
    "        for i in range(len(self.z_reverse_size)-1):\n",
    "            self.top_down_layers.append(MLP(in_size=self.z_reverse_size[i],layer_size=self.z2z_layer_size[i],out_size=self.z_reverse_size[i+1]))\n",
    "\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def bottom_up(self,input):\n",
    "        '''\n",
    "        Do the bottom up step and get z_mu_q_d and z_log_var_q_d\n",
    "\n",
    "        :param: input of ladder part,size=(batch_size * ladder_input_size)\n",
    "        :return:two lists: z_mu_q_d ,z_log_var_q_d\n",
    "        '''\n",
    "        z_mu_q_d = []\n",
    "        z_log_var_q_d = []\n",
    "        for i in range(len(self.d_size)):\n",
    "            if i == 0:\n",
    "                nn, mu_q_d, log_var_q_d = self.bottom_up_layers[i](input)\n",
    "                z_mu_q_d.append(mu_q_d)\n",
    "                z_log_var_q_d.append(log_var_q_d)\n",
    "            else:\n",
    "                nn, mu_q_d, log_var_q_d = self.bottom_up_layers[i](nn)\n",
    "                z_mu_q_d.append(mu_q_d)\n",
    "                z_log_var_q_d.append(log_var_q_d)\n",
    "        return z_mu_q_d, z_log_var_q_d # shape:[[batch_size * z_size[0]],[batch_size * z_size[1]],....,[batch_size * z_size[-1]]]\n",
    "\n",
    "    def top_down(self, z_sample, z_mu_p, z_log_var_p):\n",
    "        '''\n",
    "        Do top down step and get z_mu_p,z_log_var_p, also return samples of each level z\n",
    "\n",
    "        :param z_sample: only have the samples of top z\n",
    "        :param z_mu_p: only have the z_mu_p of top z (mu = 0)\n",
    "        :param z_log_var_p: only have the z_log_var_p of top z (var = 1)\n",
    "        :return three list :z_mu_p,z_log_var_p,z_sample\n",
    "        '''\n",
    "        for i in range(len(self.z_reverse_size) - 1):\n",
    "            _, mu_p, log_var_p = self.top_down_layers[i](z_sample[i])\n",
    "            z_sample.append(self.sample_z(mu_p, log_var_p))\n",
    "            z_mu_p.append(mu_p)\n",
    "            z_log_var_p.append(log_var_p)\n",
    "        #the shape of z_mu_p,z_log_var_p and z_sample after loop:[[batch_size * z_size[-1]],[batch_size * z_size[-2]],...[batch_size * z_size[0]]]\n",
    "        return list(reversed(z_mu_p)), list(reversed(z_log_var_p)), list(reversed(z_sample))#reverse lists of z_mu_p,z_log_var_p and z_sample\n",
    "\n",
    "    def sample_z(self, mu, log_var):\n",
    "        '''\n",
    "        Sampling z ~ p(z)= N(mu,var)\n",
    "        :return: sample of z\n",
    "        '''\n",
    "        stddev = torch.exp(log_var) ** 0.5\n",
    "        out = mu + stddev * torch.randn(mu.size()).to(self.device())\n",
    "        return out\n",
    "\n",
    "    def Gaussian_update(self, mu_q_d, log_var_q_d, mu_p, log_var_p):\n",
    "        '''\n",
    "        Combine mu_q_d,var_q_d and mu_p,var_p to generate mu_q,var_q\n",
    "        :return two tensor: mu_q,var_q\n",
    "        '''\n",
    "        var_q_d,var_p = torch.exp(log_var_q_d),torch.exp(log_var_p)\n",
    "        x = torch.pow(var_q_d, -1)\n",
    "        y = torch.pow(var_p, -1)\n",
    "        var = torch.pow(torch.add(x, y), -1)\n",
    "        mu = torch.add(mu_q_d*x, mu_p*y) * var\n",
    "        return mu, torch.log(var)\n",
    "\n",
    "    def KL_loss(self,q_mu,q_log_var,p_mu,p_log_var):\n",
    "        q_var, p_var = torch.exp(q_log_var),torch.exp(p_log_var)\n",
    "        kl = 0.5*(p_log_var - q_log_var + q_var/p_var + torch.pow(torch.add(q_mu,-p_mu),2)/p_var -1)\n",
    "        return kl.sum(1).mean()\n",
    "\n",
    "    def forward_latent(self,input):\n",
    "        # initialize required lists\n",
    "        z_mu_p = []\n",
    "        z_log_var_p = []\n",
    "        z_sample = []\n",
    "        z_mu_q = []\n",
    "        z_log_var_q = []\n",
    "        kl_loss = 0\n",
    "\n",
    "        #do bottom up step and get z_mu_q_d, z_log_var_q_d\n",
    "        z_mu_q_d, z_log_var_q_d = self.bottom_up(input)# [[batch_size * z_size[0]],[batch_size * z_size[1]],...,[batch_size * z_size[-1]]]\n",
    "\n",
    "        #add mu_p,var_p and samples of top z to list\n",
    "        z_mu_p.append(torch.zeros(z_mu_q_d[-1].size()).to(self.device())) #[[batch_size * z_size[-1]]]\n",
    "        z_log_var_p.append(torch.zeros(z_log_var_q_d[-1].size()).to(self.device())) #[[batch_size * z_size[-1]]]\n",
    "        z_sample.append(self.sample_z(z_mu_q_d[-1], z_log_var_q_d[-1])) #[[batch_size * z_size[-1]]]\n",
    "\n",
    "        #do top down step and get z_mu_p, z_log_var_p,z_sample\n",
    "        z_mu_p, z_log_var_p, z_sample = self.top_down(z_sample, z_mu_p, z_log_var_p)# [[batch_size * z_size[0]],[batch_size * z_size[1]],...,[batch_size * z_size[-1]]]\n",
    "\n",
    "        #combine z_mu_q_d, z_log_var_q_d, z_mu_p, z_log_var_p to generate z_mu_q and z_log_var_q\n",
    "        for i in range(len(self.z_size)-1):\n",
    "            mu, log_var = self.Gaussian_update(z_mu_q_d[i], z_log_var_q_d[i], z_mu_p[i], z_log_var_p[i])\n",
    "            z_mu_q.append(mu)\n",
    "            z_log_var_q.append(log_var)\n",
    "        z_mu_q.append(z_mu_q_d[-1])\n",
    "        z_log_var_q.append(z_log_var_q_d[-1])\n",
    "        # the shape of z_mu_q,z_log_var_q: [[batch_size * z_size[0]],[batch_size * z_size[1]],...,[batch_size * z_size[-1]]]\n",
    "\n",
    "        #calculate KL_loss\n",
    "        for i in range(len(self.z_size)):\n",
    "            kl_loss = kl_loss + self.KL_loss(z_mu_q[i], z_log_var_q[i], z_mu_p[i], z_log_var_p[i])\n",
    "        return z_sample[0],kl_loss\n",
    "\n",
    "    def forward(self, batch):\n",
    "        _,h = self.encoder(batch)\n",
    "        #print(\"1:\",h.item())\n",
    "        \n",
    "        z,KL_loss = self.forward_latent(h)\n",
    "        \n",
    "        #print(\"2:\",z.item(),KL_loss.item())\n",
    "        recon_loss = self.decoder(batch,z)\n",
    "        return KL_loss,recon_loss\n",
    "\n",
    "    def tensor2string(self, tensor):\n",
    "        ids = tensor.tolist()\n",
    "        string = self.vocab.ids2string(ids, rem_bos=True, rem_eos=True)\n",
    "        return string\n",
    "\n",
    "    def sample(self,n_batch,max_len=100,temp=1.0,z=None):\n",
    "        '''\n",
    "        Generating n_batch samples\n",
    "\n",
    "        :param n_batch: number of sentences to generate\n",
    "        :param max_len: max len of samples\n",
    "        :param temp: temperature of softmax\n",
    "        :param z: (n_batch, ladder_z_size[-1]) of floats, vector of top z or None\n",
    "        :return: list of tensors of strings, samples sequence x\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            # get samples of  z\n",
    "            z_sample = []\n",
    "            z_mu_p = []\n",
    "            z_log_var_p =[]\n",
    "            z_mu_p.append(torch.zeros(n_batch,self.z_size[-1]).to(self.device()))\n",
    "            z_log_var_p.append(torch.zeros(n_batch, self.z_size[-1]).to(self.device()))\n",
    "            if z is not None:\n",
    "                z_sample.append(z.to(self.device()))\n",
    "            else:\n",
    "                z_sample.append(self.sample_z(z_mu_p[0], z_log_var_p[0]))\n",
    "            _,_,z_sample = self.top_down(z_sample,z_mu_p,z_log_var_p)\n",
    "            z = z_sample[0].unsqueeze(1) # n_batch * 1 * ladder_z_size[0]\n",
    "\n",
    "            # inital values\n",
    "            h = self.decoder.map_z2hc(z_sample[0]) # n_batch * dec_hid_sz *2\n",
    "            h_0, c_0 = h[:,:self.decoder.d_d_h], h[:,self.decoder.d_d_h:] # n_batch * dec_hid_sz\n",
    "            h_0 = h_0.unsqueeze(0).repeat(self.decoder.lstm.num_layers, 1, 1)  # dec_n_layer * n_batch * dec_hid_sz\n",
    "            c_0 = c_0.unsqueeze(0).repeat(self.decoder.lstm.num_layers, 1, 1)  # dec_n_layer * n_batch * dec_hid_sz\n",
    "            w = torch.tensor(self.bos).repeat(n_batch).to(self.device()) # n_batch\n",
    "            x = torch.tensor([self.pad]).repeat(n_batch,max_len).to(self.device()) # n_batch * max_len\n",
    "\n",
    "            x[:, 0] = self.bos\n",
    "            end_pads = torch.tensor([max_len]).to(self.device()).repeat(n_batch) # a tensor record the length of each molecule, size=n_batch\n",
    "            eos_mask = torch.zeros(n_batch, dtype=torch.bool).to(self.device()) # a tensor indicate the molecular generation process is over or not,size=n_batch\n",
    "\n",
    "            # generating cycle\n",
    "            for i in range(1,max_len):\n",
    "                x_emb = self.embedding(w).unsqueeze(1) # n_batch * 1 * embed_size\n",
    "                x_input = torch.cat([x_emb, z], dim=-1) # n_batch * 1 * (embed_size + ladder_z_size[0])\n",
    "                output, (h_0,c_0) = self.decoder.lstm(x_input, (h_0,c_0)) # output size : n_batch * 1 * dec_hid_sz\n",
    "                y = self.decoder.decoder_fc(output.squeeze(1))\n",
    "                y = F.softmax(y / temp, dim=-1) # n_batch * n_vocab\n",
    "\n",
    "                w = torch.multinomial(y, 1)[:, 0] # input of next generate step, size=n_batch\n",
    "                x[~eos_mask, i] = w[~eos_mask] # add generated atom to molecule\n",
    "                i_eos_mask = ~eos_mask & (w == self.eos)\n",
    "                end_pads[i_eos_mask] = i + 1 # update end_pads\n",
    "                eos_mask = eos_mask | i_eos_mask #update eos_mask\n",
    "\n",
    "            # Converting `x` to list of tensors\n",
    "            new_x = []\n",
    "            for i in range(x.size(0)):\n",
    "                new_x.append(x[i, :end_pads[i]])\n",
    "            return [self.tensor2string(i_x) for i_x in new_x]\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self,in_size,layer_size,out_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.layer1 = nn.Linear(in_size,layer_size)\n",
    "        self.layer2 = nn.Linear(layer_size,layer_size)\n",
    "        self.mu = nn.Linear(layer_size,out_size)\n",
    "        self.var = nn.Linear(layer_size,out_size)\n",
    "\n",
    "    def forward(self,input):\n",
    "        layer1 = F.leaky_relu(self.layer1(input))\n",
    "        layer2 = F.leaky_relu(self.layer2(layer1))\n",
    "        mu = self.mu(layer2)\n",
    "        var = F.softplus(self.var(layer2)) + 1e-8\n",
    "        return layer2,mu,var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DatasetSplit as DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: '#',\n",
       " 1: '(',\n",
       " 2: ')',\n",
       " 3: '+',\n",
       " 4: '-',\n",
       " 5: '1',\n",
       " 6: '2',\n",
       " 7: '3',\n",
       " 8: '4',\n",
       " 9: '5',\n",
       " 10: '6',\n",
       " 11: '7',\n",
       " 12: '8',\n",
       " 13: '9',\n",
       " 14: '=',\n",
       " 15: 'B',\n",
       " 16: 'C',\n",
       " 17: 'F',\n",
       " 18: 'H',\n",
       " 19: 'I',\n",
       " 20: 'N',\n",
       " 21: 'O',\n",
       " 22: 'P',\n",
       " 23: 'S',\n",
       " 24: '[',\n",
       " 25: ']',\n",
       " 26: 'c',\n",
       " 27: 'l',\n",
       " 28: 'n',\n",
       " 29: 'o',\n",
       " 30: 'p',\n",
       " 31: 'r',\n",
       " 32: 's',\n",
       " 33: '<bos>',\n",
       " 34: '<eos>',\n",
       " 35: '<pad>',\n",
       " 36: '<unk>'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = DS(\"train\",\"../data/train.csv\")\n",
    "vocab = train_split._vocab\n",
    "vocab.i2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(clip_grad=50, dec_hid_sz=256, dec_n_layer=1, dec_type='lstm', device='cpu', dropout=0.1, emb_sz=128, enc_bidirectional=False, enc_hidden_size=256, enc_num_layers=1, enc_sorted_seq=True, enc_type='lstm', kl_anr_type='const', kl_e_start=1, kl_w_end=1.0, kl_w_start=1.0, ladder_d_size=[512, 256, 128, 64, 32], ladder_z2z_layer_size=[8, 16, 32, 64], ladder_z_size=[64, 32, 16, 8, 4], log_path=None, loss_buf_sz=1000, lr_anr_type='const', lr_end=0.00030000000000000003, lr_mult_coeff=1, lr_n_restarts=10, lr_period=10, lr_start=0.00030000000000000003, model_save=None, n_epoch=100, save_frequency=10, seed=56, test_load='../data/valid.csv', train_bsz=512, train_load='../data/train.csv', valid_load='../data/valid.csv')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"test_batch.bsz-2.pkl\",\"rb\") as fi:\n",
    "    tb = pickle.load(fi)\n",
    "\n",
    "from opt import get_parser\n",
    "parser = get_parser()\n",
    "config = parser.parse_args([])\n",
    "\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12.5257, grad_fn=<AddBackward0>),\n",
       " tensor(3.6320, grad_fn=<NllLossBackward>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "model = LVAE(vocab, config)\n",
    "\n",
    "model((tb[0],tb[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '#',\n",
       " 1: '(',\n",
       " 2: ')',\n",
       " 3: '+',\n",
       " 4: '-',\n",
       " 5: '1',\n",
       " 6: '2',\n",
       " 7: '3',\n",
       " 8: '4',\n",
       " 9: '5',\n",
       " 10: '6',\n",
       " 11: '7',\n",
       " 12: '=',\n",
       " 13: 'B',\n",
       " 14: 'C',\n",
       " 15: 'F',\n",
       " 16: 'H',\n",
       " 17: 'I',\n",
       " 18: 'N',\n",
       " 19: 'O',\n",
       " 20: 'P',\n",
       " 21: 'S',\n",
       " 22: '[',\n",
       " 23: ']',\n",
       " 24: 'c',\n",
       " 25: 'l',\n",
       " 26: 'n',\n",
       " 27: 'o',\n",
       " 28: 'r',\n",
       " 29: 's',\n",
       " 30: '<bos>',\n",
       " 31: '<eos>',\n",
       " 32: '<pad>',\n",
       " 33: '<unk>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.i2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=t.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hiensg)",
   "language": "python",
   "name": "hiensg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
